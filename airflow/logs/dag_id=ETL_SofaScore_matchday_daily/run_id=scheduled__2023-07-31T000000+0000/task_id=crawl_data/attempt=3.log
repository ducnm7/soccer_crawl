[2024-07-27T16:30:58.693+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-27T16:30:58.716+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ETL_SofaScore_Matchday_daily.crawl_data scheduled__2023-07-31T00:00:00+00:00 [queued]>
[2024-07-27T16:30:58.726+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ETL_SofaScore_Matchday_daily.crawl_data scheduled__2023-07-31T00:00:00+00:00 [queued]>
[2024-07-27T16:30:58.727+0000] {taskinstance.py:2306} INFO - Starting attempt 3 of 4
[2024-07-27T16:30:58.881+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_data> on 2023-07-31 00:00:00+00:00
[2024-07-27T16:30:58.889+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=2783) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-27T16:30:58.891+0000] {standard_task_runner.py:63} INFO - Started process 2785 to run task
[2024-07-27T16:30:58.891+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ETL_SofaScore_Matchday_daily', 'crawl_data', 'scheduled__2023-07-31T00:00:00+00:00', '--job-id', '369', '--raw', '--subdir', 'DAGS_FOLDER/crawl_dags.py', '--cfg-path', '/tmp/tmp1mhv1xta']
[2024-07-27T16:30:58.893+0000] {standard_task_runner.py:91} INFO - Job 369: Subtask crawl_data
[2024-07-27T16:30:58.942+0000] {task_command.py:426} INFO - Running <TaskInstance: ETL_SofaScore_Matchday_daily.crawl_data scheduled__2023-07-31T00:00:00+00:00 [running]> on host fde3e54b98e9
[2024-07-27T16:30:59.024+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='nguyenmduc2407@gmail.com' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ETL_SofaScore_Matchday_daily' AIRFLOW_CTX_TASK_ID='crawl_data' AIRFLOW_CTX_EXECUTION_DATE='2023-07-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-07-31T00:00:00+00:00'
[2024-07-27T16:30:59.026+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-27T16:31:00.942+0000] {logging_mixin.py:188} INFO - Dataframe is here!!!
[2024-07-27T16:31:01.114+0000] {logging_mixin.py:188} INFO -       customId  winnerCode  ...  awayScore_extra2 awayScore_overtime
0      kYcsmYc         2.0  ...               NaN                NaN
1      vYcsDPi         3.0  ...               NaN                NaN
2    Didbsbxpc         2.0  ...               NaN                NaN
3      tYcswXo         1.0  ...               NaN                NaN
4      nYcspYc         2.0  ...               NaN                NaN
..         ...         ...  ...               ...                ...
234    GoksUjn         1.0  ...               NaN                NaN
235     EPsTkk         3.0  ...               NaN                NaN
236    ZTqsoGB         2.0  ...               NaN                NaN
237     UHsXdb         2.0  ...               NaN                NaN
238   KrcsBHtb         3.0  ...               NaN                NaN

[239 rows x 129 columns]
[2024-07-27T16:31:01.385+0000] {logging_mixin.py:188} INFO - Data has been written to the database.
[2024-07-27T16:31:01.392+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-07-27T16:31:01.393+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-27T16:31:01.402+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ETL_SofaScore_Matchday_daily, task_id=crawl_data, run_id=scheduled__2023-07-31T00:00:00+00:00, execution_date=20230731T000000, start_date=20240727T163058, end_date=20240727T163101
[2024-07-27T16:31:01.436+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-27T16:31:01.466+0000] {taskinstance.py:3498} INFO - 7 downstream tasks scheduled from follow-on schedule check
[2024-07-27T16:31:01.469+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-27T17:26:28.407+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-27T17:26:28.430+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ETL_SofaScore_Matchday_daily.crawl_data scheduled__2023-07-31T00:00:00+00:00 [queued]>
[2024-07-27T17:26:28.439+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ETL_SofaScore_Matchday_daily.crawl_data scheduled__2023-07-31T00:00:00+00:00 [queued]>
[2024-07-27T17:26:28.440+0000] {taskinstance.py:2306} INFO - Starting attempt 3 of 4
[2024-07-27T17:26:28.592+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_data> on 2023-07-31 00:00:00+00:00
[2024-07-27T17:26:28.600+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=3658) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-27T17:26:28.602+0000] {standard_task_runner.py:63} INFO - Started process 3660 to run task
[2024-07-27T17:26:28.601+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ETL_SofaScore_Matchday_daily', 'crawl_data', 'scheduled__2023-07-31T00:00:00+00:00', '--job-id', '422', '--raw', '--subdir', 'DAGS_FOLDER/crawl_dags.py', '--cfg-path', '/tmp/tmpgcj0lj59']
[2024-07-27T17:26:28.603+0000] {standard_task_runner.py:91} INFO - Job 422: Subtask crawl_data
[2024-07-27T17:26:28.656+0000] {task_command.py:426} INFO - Running <TaskInstance: ETL_SofaScore_Matchday_daily.crawl_data scheduled__2023-07-31T00:00:00+00:00 [running]> on host fde3e54b98e9
[2024-07-27T17:26:28.743+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='nguyenmduc2407@gmail.com' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ETL_SofaScore_Matchday_daily' AIRFLOW_CTX_TASK_ID='crawl_data' AIRFLOW_CTX_EXECUTION_DATE='2023-07-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-07-31T00:00:00+00:00'
[2024-07-27T17:26:28.745+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-27T17:26:30.431+0000] {logging_mixin.py:188} INFO - Dataframe is here!!!
[2024-07-27T17:26:30.507+0000] {logging_mixin.py:188} INFO -       customId  winnerCode  ...  awayScore_extra2 awayScore_overtime
0      kYcsmYc         2.0  ...               NaN                NaN
1      vYcsDPi         3.0  ...               NaN                NaN
2    Didbsbxpc         2.0  ...               NaN                NaN
3      tYcswXo         1.0  ...               NaN                NaN
4      nYcspYc         2.0  ...               NaN                NaN
..         ...         ...  ...               ...                ...
234    GoksUjn         1.0  ...               NaN                NaN
235     EPsTkk         3.0  ...               NaN                NaN
236    ZTqsoGB         2.0  ...               NaN                NaN
237     UHsXdb         2.0  ...               NaN                NaN
238   KrcsBHtb         3.0  ...               NaN                NaN

[239 rows x 129 columns]
[2024-07-27T17:26:30.760+0000] {logging_mixin.py:188} INFO - Data has been written to the database.
[2024-07-27T17:26:30.766+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-07-27T17:26:30.767+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-27T17:26:30.777+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ETL_SofaScore_Matchday_daily, task_id=crawl_data, run_id=scheduled__2023-07-31T00:00:00+00:00, execution_date=20230731T000000, start_date=20240727T172628, end_date=20240727T172630
[2024-07-27T17:26:30.825+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-27T17:26:30.857+0000] {taskinstance.py:3498} INFO - 7 downstream tasks scheduled from follow-on schedule check
[2024-07-27T17:26:30.861+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
