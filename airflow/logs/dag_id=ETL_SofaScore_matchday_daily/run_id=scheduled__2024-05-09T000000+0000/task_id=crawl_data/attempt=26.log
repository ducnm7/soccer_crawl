[2024-05-21T15:47:13.516+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-21T15:47:13.538+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ETL_SofaScore_matchday_daily.crawl_data scheduled__2024-05-09T00:00:00+00:00 [queued]>
[2024-05-21T15:47:13.548+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ETL_SofaScore_matchday_daily.crawl_data scheduled__2024-05-09T00:00:00+00:00 [queued]>
[2024-05-21T15:47:13.549+0000] {taskinstance.py:2306} INFO - Starting attempt 26 of 27
[2024-05-21T15:47:13.751+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_data> on 2024-05-09 00:00:00+00:00
[2024-05-21T15:47:13.757+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1013) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-05-21T15:47:13.758+0000] {standard_task_runner.py:63} INFO - Started process 1015 to run task
[2024-05-21T15:47:13.758+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ETL_SofaScore_matchday_daily', 'crawl_data', 'scheduled__2024-05-09T00:00:00+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/crawl_dags.py', '--cfg-path', '/tmp/tmpv0ybucb7']
[2024-05-21T15:47:13.760+0000] {standard_task_runner.py:91} INFO - Job 60: Subtask crawl_data
[2024-05-21T15:47:13.806+0000] {task_command.py:426} INFO - Running <TaskInstance: ETL_SofaScore_matchday_daily.crawl_data scheduled__2024-05-09T00:00:00+00:00 [running]> on host dbddc4e9ac3f
[2024-05-21T15:47:13.892+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='nguyenmduc2407@gmail.com' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ETL_SofaScore_matchday_daily' AIRFLOW_CTX_TASK_ID='crawl_data' AIRFLOW_CTX_EXECUTION_DATE='2024-05-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='26' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-09T00:00:00+00:00'
[2024-05-21T15:47:13.893+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-21T15:47:14.701+0000] {logging_mixin.py:188} INFO - Dataframe is here!!!
[2024-05-21T15:47:14.776+0000] {logging_mixin.py:188} INFO -      customId  winnerCode  ...  awayScore_penalties  time_injuryTime4
0     xdbsEgb         1.0  ...                  NaN               NaN
1      QHsLdb         1.0  ...                  NaN               NaN
2     Gdbsceb         3.0  ...                  NaN               NaN
3     TdbsNhb         3.0  ...                  NaN               NaN
4       PsVob         1.0  ...                  NaN               NaN
..        ...         ...  ...                  ...               ...
173  jPisvQDb         1.0  ...                  4.0               3.0
174  MucsBpFb         2.0  ...                  NaN               NaN
175   Fknsvmn         1.0  ...                  NaN               NaN
176   AmnsEmn         1.0  ...                  NaN               NaN
177  FmnsvARb         2.0  ...                  NaN               NaN

[178 rows x 140 columns]
[2024-05-21T15:47:15.406+0000] {logging_mixin.py:188} INFO - Data has been written to the database.
[2024-05-21T15:47:15.478+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-21T15:47:15.479+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-21T15:47:15.489+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ETL_SofaScore_matchday_daily, task_id=crawl_data, run_id=scheduled__2024-05-09T00:00:00+00:00, execution_date=20240509T000000, start_date=20240521T154713, end_date=20240521T154715
[2024-05-21T15:47:15.539+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-21T15:47:15.558+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-05-21T15:47:15.561+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
